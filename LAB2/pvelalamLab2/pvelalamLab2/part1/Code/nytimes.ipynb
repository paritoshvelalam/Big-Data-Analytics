{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nytimesarticle import articleAPI\n",
    "api = articleAPI('n8WGUINlTFaJQ436UBsOf0OGU1SBymFb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectarticles_url(articles):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for i in articles['response']['docs']:\n",
    "        urls = {}  \n",
    "        urls['url'] = i['web_url']\n",
    "        res = urls['url']\n",
    "        result.append(res)\n",
    "        \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our query words = [ Baseball, Basketball, N.F.L., Soccer, Tennis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "result1 = []\n",
    "for date in range(20190101,20190130):\n",
    "    for i in range(0,100):\n",
    "        try:\n",
    "            print(date,\" \",i)\n",
    "            articles1 = api.search( q = 'Tennis',begin_date = date,end_date = date+1, page=i)\n",
    "            res = collectarticles_url(articles1)\n",
    "            if len(res) != 0:\n",
    "                result1 = result1 + collectarticles_url(articles1)\n",
    "                time.sleep(6)\n",
    "            else:\n",
    "                time.sleep(6)\n",
    "                break\n",
    "        except BaseException:\n",
    "            print(\"exception\")\n",
    "\n",
    "for date in range(20190201,20190227):\n",
    "    for i in range(0,100):\n",
    "        try:\n",
    "            print(date,\" \",i)\n",
    "            articles1 = api.search( q = 'Tennis',begin_date = date,end_date = date+1, page=i)\n",
    "            res = collectarticles_url(articles1)\n",
    "            if len(res) != 0:\n",
    "                result1 = result1 + collectarticles_url(articles1)\n",
    "                time.sleep(6)\n",
    "            else:\n",
    "                time.sleep(6)\n",
    "                break\n",
    "        except BaseException:\n",
    "            print(\"exception\")\n",
    "            \n",
    "for date in range(20190301,20190330):\n",
    "    for i in range(0,100):\n",
    "        try:\n",
    "            print(date,\" \",i)\n",
    "            articles1 = api.search( q = 'Tennis',begin_date = date,end_date = date+1, page=i)\n",
    "            res = collectarticles_url(articles1)\n",
    "            if len(res) != 0:\n",
    "                result1 = result1 + res\n",
    "                time.sleep(6)\n",
    "            else:\n",
    "                time.sleep(6)\n",
    "                break\n",
    "        except BaseException:\n",
    "            print(\"exception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nytimes = list(set(result1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = len(data_nytimes)\n",
    "data_nytimes1 = data_nytimes[1:rows]\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import csv\n",
    "\n",
    "final_list = []\n",
    "\n",
    "for listobs in data_nytimes1:\n",
    "    try:\n",
    "        r = urllib.request.urlopen(listobs).read()\n",
    "        soup = BeautifulSoup(r)\n",
    "        text_iter = soup.findAll('p')\n",
    "\n",
    "        finaltext = \"\"\n",
    "\n",
    "        for tag in text_iter:\n",
    "            finaltext = finaltext + tag.getText()\n",
    "        final_list.append(finaltext)\n",
    "    except BaseException:\n",
    "        print(Exception)\n",
    "        print(listobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(final_list)\n",
    "df.to_csv('Tennis.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data_nytimes1)\n",
    "df.to_csv('Tennislinks.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
